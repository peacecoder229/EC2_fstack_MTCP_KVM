shares:
  shared-storage-partition: /mnt/nvme_nfs_share/AIBench_shared_disk
  disk1-storage: /mnt/nvme_local
  logs-location: /tmp/aibench/runs/$RUN_ID

virtual-instances:
  text-to-speech-inference:
    repeat-count: 1                                     # number of instances to launch
    #cores: 0-55                                         # number of cores (divided uniformly among all instances)
    services: ssh                                       # opens port 22
    env:
      PRESET_PATH: ${shares.shared-storage-partition}/Data/text-to-speech-inference/20180505_deepvoice3_ljspeech.json                    # Path of preset parameters (json)
      CHECKPOINT_PATH: ${shares.shared-storage-partition}/Data/text-to-speech-inference/20180505_deepvoice3_checkpoint_step000640000.pth # pretrained model path 
      INPUT_TXT_PATH: ${shares.shared-storage-partition}/Data/text-to-speech-inference/sentences.txt                                     # input text file path - LJSpeech dataset
      OUTPUT_DIR: ${shares.logs-location}                                                                                 # path where the converted audio wav is to be saved
      SPEAKER_ID: None                                                                                                    # Speaker ID (for multi-speaker model)(None for LJspeech,0-108 for vctk)
      KMP_BLOCKTIME: 1
      LOGSTASH_HOST: db-server-0.aibench-static
      LOGSTASH_PORT: 5959
      LOG_LEVEL: INFO                                   # INFO or DEBUG, use DEBUG for detailed event collection

scenarios:
  text-to-speech-inference:
    virtual-instances: text-to-speech-inference
    parser: parser-tts.py
