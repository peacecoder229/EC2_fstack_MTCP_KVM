# FFMPEG Workload User's Guide

This user's guide covers the following topics:

- **1. Listing and Running Pre-Defined Tests**
- **2. Running the FFMPEG Workload On-Premises**
- **3. Output Files Generated by the FFMPEG Workload Tests**
- **4. Interpreting the results.csv File**
- **5. The FFMPEG Workload Description File**
- **6. Creating and Using a Custom FFMPEG Workload Description File**
- **7. Using Separate Provision, Prepare, and Run Stages**
- **8. Using Cached Input Video Files**
- **9. Copying Prepared Videos from the SUT**
- **10. Publishing Results to the Cumulus Dashboard**
- **11. Output Modes and Autoscaling**
- **12. Using Trace Collectors, Such as EMON**
- **13. Running a Specific Number of FFMPEG Instances**
- **14. Using Direct Mode**
- **15. Adding Your Own Input Videos**

It is assumed you have already set up a cloud service provider account and are familiar with general PKB/Cumulus topics.

## 1. Listing and Running Pre-Defined Tests

The FFMPEG workload has a number of tests that are available to be run. Each of these tests is defined in the default FFMPEG workload description file, [ffmpeg_benchmark_tests.yaml](ffmpeg_benchmark_tests.yaml), which is located in PKB's perfkitbenchmarker/data/ffmpeg directory.

To see the tests that are available by default, you may use the *--get_bechmark_usage* command line option, as follows: 

```bash
$ ./pkb.py --benchmarks=ffmpeg --get_benchmark_usage
```

The output, a listing of each test available along with a short description, should look similar to the following:

```bash
FFMPEG benchmark description file:
  '/home/ubuntu/src/perfkitbenchmarker/perfkitbenchmarker/data/ffmpeg/ffmpeg_benchmark_tests.yaml'
Available FFMPEG benchmark tests:
  all                                 # Run all ffmpeg benchmark tests
  svt-hevc                            # Run all ffmpeg benchmark tests that use the svt-hevc codec
  svt-hevc-0-1to1VOD-1080p            # 1080P input to 1080P output using SVT-HEVC/0/2
  svt-hevc-0-1to1VOD-4k               # 4k input to 4k output using SVT-HEVC/0/2
  svt-hevc-4-1to1VOD-1080p            # 1080P input to 1080P output using SVT-HEVC/4/2
  svt-hevc-4-1to1VOD-4k               # 4k input to 4k output using SVT-HEVC/4/2
  svt-hevc-preset10-1to1Live-4k       # 4k input to 4k output using hevc/10
  svt-hevc-preset6-1to1Live-1080p     # 1080p input to 1080P output using hevc/6
  svt-hevc-preset6-1to1Live-4k        # 4k input to 4k output using hevc/6
  svt-hevc-preset6-1toNLive-1080p     # 1080p input to multiple outputs using hevc/6
  svt-hevc-preset6-1toNLive-4k        # 4k input to multiple outputs using hevc/6
  svt-hevc-preset9-1to1Live-1080p     # 1080p input to 1080P output using hevc/9
  svt-hevc-preset9-1toNLive-1080p     # 1080p input to multiple outputs using hevc/9
  svt-hevc-preset9-1toNLive-4k        # 4k input to multiple outputs using hevc/9
  vod                                 # Run all VOD benchmark tests
  x264                                # Run all ffmpeg benchmark tests that use the x264 codec
  x264-medium-1to1Live-1080p          # 1080p input to 1080P output using x264/medium
  x264-medium-1toNLive-1080p          # 1080p input to multiple outputs using x264/medium
  x264-veryfast-1to1Live-1080p        # 1080p input to 1080P output using x264/veryfast
  x264-veryfast-1toNLive-1080p        # 1080p input to multiple outputs using x264/veryfast
  x264-veryslow-1to1VOD-1080p         # 1080P input to 1080P output using x264/veryslow
  x265                                # Run all ffmpeg benchmark tests that use the x265 codec
  x265-medium-1to1Live-1080p          # 1080p input to 1080p output using x265/medium
  x265-medium-1to1Live-4k             # 4k input to 4k output using x265/medium
  x265-medium-1toNLive-1080p          # 1080p input to multiple outputs using x265/medium
  x265-medium-1toNLive-4k             # 4k input to multiple outputs using x265/medium
  x265-veryfast-1to1Live-1080p        # 1080p input to 1080p output using x265/veryfast
  x265-veryfast-1to1Live-4k           # 4k input to 4k output using x265/veryfast
  x265-veryfast-1toNLive-1080p        # 1080p input to multiple outputs using x265/veryfast
  x265-veryfast-1toNLive-4k           # 4k input to multiple outputs using x265/veryfast
  x265-veryslow-1to1VOD-1080p         # 1080P input to 1080P output using x265/veryslow
  x265-veryslow-1to1VOD-4k            # 4K input to 4K output using x265/veryslow
```

These benchmark tests (the names on the left side of the output shown above) can be used on the command line to specify which tests to run. For example, the following command line will run the *x264-veryfast-1to1Live-1080p* test on an AWS m5.16xlarge instance running Ubuntu 16.04 and should take about 10 minutes or so to complete:

```bash
$ ./pkb.py --cloud=AWS --machine_type=m5.16xlarge --os_type=ubuntu1804 --zone=us-west-2 --benchmarks=ffmpeg --ffmpeg_run_tests=x264-veryfast-1to1Live-1080p
```

The *--ffmpeg_run_tests* option takes a comma-separated list of test names to allow more than one test to be specified at a time. For example, the following command line runs both the *x264-medium-10to1Live-1800p* and *x265-veryfast-1to1Live-1080p* tests:

```bash
$ ./pkb.py --cloud=AWS --machine_type=m5.16xlarge --os_type=ubuntu1804 --zone=us-west-2 --benchmarks=ffmpeg --ffmpeg_run_tests=x264-medium-10to1Live-1800p,x265-veryfast-1to1Live-1080p
```

Some of the names in the benchmark description file, such as *all, x264, x265, vod,* and *svt-hevc*, are groups of tests. These are used the same as any other test name. For example, the following executes all x264 tests and the x265-medium-1to1Live-1080p test:

```bash
$ ./pkb.py --cloud=AWS --machine_type=m5.16xlarge --os_type=ubuntu1804 --zone=us-west-2 --benchmarks=ffmpeg --ffmpeg_run_tests=x264,x265-medium-1to1Live-1080p
```

Be aware that groups of tests can take a very long time to run.

## 2. Running the FFMPEG Workload On-Premises

To run the FFMPEG workload on-premises instead of using a cloud service provider, you must provide a benchmark configuration file that specifies the details of the target SUT. The YAML-formatted benchmark configuration file lists one or more "static VMs" under the 'static_vms' key. Each entry provides information about the SUT, including its IP address, the location of the SSH private key on the SUT, etc. For example, 

```YAML
# my_benchmark_config.yaml
static_vms:
  - &vm0
    ip_address: 10.54.27.79
    user_name: pkbuser
    ssh_private_key: ~/.ssh/id_rsa
    internal_ip: 10.54.27.79

ffmpeg:
  vm_groups:
    default:
      static_vms:
        - *vm0
```

The PKB command line option, *--benchmark_config_file*, is then used to specify the configuration file. For example,

```bash
$ ./pkb.py --benchmark_config_file=/home/myusername/my_benchmark_config.yaml --benchmarks=ffmpeg --ffmpeg_run_tests=svt-hevc-preset9-1toNLive-1080p 
```

You can find more information about running on-premises [here](https://wiki.ith.intel.com/display/cloudperf/How+to+run+PKB+On-Prem).

## 3. Output Files Generated by the FFMPEG Workload Tests

For each run, PKB generates a unique *run URI*, which is used to identify the run. By default, output files for a run are stored in the */tmp/perfkitbenchmarker/runs/\<run-uri\>* directory. For example, assuming PKB generated a URI value of '9cb603ff' for the run, the output files for the run are stored at */tmp/perfkitbenchmarker/runs/9cb603ff*.

There are several files of interest in the output directory, including:

- **pkb.log**

    The PKB log file, pkb.log, is a log file of the entire run and is helpful when debugging problems with a run.

- **perfkitbenchmarker_results.json**

    The workload outputs a JSON file that contains the results of each test in the run and a couple summary entries: the % of tests passed and the overall execution time for the entire run.

- **results_dir.tar.gz**

    This file is an archive of all of the output for a run, collected on the SUT after a run and transferred to the host. It includes intermediate results and log files as well as any trace collector output (such as EMON). On the SUT, output data for a run is collected in the directory /opt/pkb/results/result_*\<timestamp\>*, where *\<timestamp\>* is a timestamp created at the time of the run.

    Here is the structure of an example results_dir file:

    ```code
    opt/pkb/results/results_2020-08-07_09:58:33/x264/1080P/1:1/LIVE/veryfast/crowd_run_1080p50_x264.mp4/8_instance/
    opt/pkb/results/results_2020-08-07_09:58:33/x264/1080P/1:1/LIVE/veryfast/crowd_run_1080p50_x264.mp4/10_instance/
    opt/pkb/results/results_2020-08-07_09:58:33/x264/1080P/1:1/LIVE/veryfast/crowd_run_1080p50_x264.mp4/11_instance/
    opt/pkb/results/results_2020-08-07_09:58:33/x264/1080P/1:1/LIVE/veryfast/crowd_run_1080p50_x264.mp4/10_instance_w_traces
    ```

    There is a directory for each pass of the autoscaling process which contains the output files for that pass. In this case, the autoscaler tried 8 instances (which succeeded), then 10 instances (which succeeded), then 11 instances (which failed). In this particular case, trace collection was requested (EMON), so there was another pass at 10 instances (the optimum # of instances in this case) with the trace collectors active.

In addition to the files in the run output directory, the FFMPEG workload generates a comma-separated variable (CSV) file in the current working directory on the host system:

- **results_*\<run-uri\>*.csv**

    This CSV file contains a concise summary of the run, including a row for each pass of the autoscaling process. This CSV file is suitable to parse or input to a tool like Microsoft Excel.
    
    The following section shows an example results file. It shows that this test had three steps in the autoscaling process, achieving 8 transcodes with a lowest fps of 76.2, then 10 transcodes with lowest fps equal to 61.2, then failing to maintain 60 fps at 11 transcodes:

  ```code
  FFMPEG Benchmark Results
  Run date/time,2020-08-07_09:58:33

  FFMPEG version,="n4.1.3-2-g070cee7184"
  Kernel version,="5.3.0-1032-aws"
  OS version    ,="Ubuntu 18.04.4 LTS"
  CPU model     ,="Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz"
  Config file   ,="/home/mjeronimo/src/perfkitbenchmarker/perfkitbenchmarker/data/ffmpeg/ffmpeg_benchmark_tests.yaml"
  Results dir   ,="/opt/pkb/results/results_2020-08-07_09:58:33"
  Video dir     ,="/opt/pkb/videos"

  codec,input_format,output_mode,n,preset,video_file,#transcodes,lowest_fps,list_of_fps,average_cpu,average_bzy_mhz,max_pct_memused,active_read_(bytes),active_write_(bytes),ffmpeg_args
  x264,1080P,="1:1",1,veryfast,crowd_run_1080p50_x264.mp4,8,76.2,="76.2/76.2/76.8/81.0/76.2/82.8/82.2/81.0",80.63,2842.46,13758660.0,108971478.16,5571.60,"-i crowd_run_1080p50_x264.mp4 -c:v libx264 -preset veryfast -filter_scale_threads 4 -profile:v main -refs 3 -g 60 -keyint_min 60 -b:v 6M -maxrate 6M -bufsize 12M -sc_threshold 0 -r 60 -y 1080p.mp4"
  x264,1080P,="1:1",1,veryfast,crowd_run_1080p50_x264.mp4,10,61.2,="69.0/61.8/69.0/68.4/69.6/61.2/61.2/68.4/62.4/61.2",82.23,2827.07,16032820.0,17415586.69,5052.12,"-i crowd_run_1080p50_x264.mp4 -c:v libx264 -preset veryfast -filter_scale_threads 4 -profile:v main -refs 3 -g 60 -keyint_min 60 -b:v 6M -maxrate 6M -bufsize 12M -sc_threshold 0 -r 60 -y 1080p.mp4"
  x264,1080P,="1:1",1,veryfast,crowd_run_1080p50_x264.mp4,11,56.22,="56.22/57.06/59.34/59.88/56.34/57.18/59.1/59.46/59.58/58.86/57.06",82.84,2832.89,17206068.0,21058730.17,5265.87,"-i crowd_run_1080p50_x264.mp4 -c:v libx264 -preset veryfast -filter_scale_threads 4 -profile:v main -refs 3 -g 60 -keyint_min 60 -b:v 6M -maxrate 6M -bufsize 12M -sc_threshold 0 -r 60 -y 1080p.mp4"

  Total Runtime: 0:04:56.764700
   ```

## 4. Interpreting the results.csv File

Following is a sample output for a workload run on an Intel Xeon(R) Platinum 8175M CPU:

  ```code
  FFMPEG Benchmark Results
  Run date/time,2020-08-07_09:58:33

  FFMPEG version,="n4.1.3-2-g070cee7184"
  Kernel version,="5.3.0-1032-aws"
  OS version    ,="Ubuntu 18.04.4 LTS"
  CPU model     ,="Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz"
  Config file   ,="/home/mjeronimo/src/perfkitbenchmarker/perfkitbenchmarker/data/ffmpeg/ffmpeg_benchmark_tests.yaml"
  Results dir   ,="/opt/pkb/results/results_2020-08-07_09:58:33"
  Video dir     ,="/opt/pkb/videos"

  codec,input_format,output_mode,n,preset,video_file,#transcodes,lowest_fps,list_of_fps,average_cpu,average_bzy_mhz,max_pct_memused,active_read_(bytes),active_write_(bytes),ffmpeg_args
  x264,1080P,="1:1",1,veryfast,crowd_run_1080p50_x264.mp4,8,76.2,="76.2/76.2/76.8/81.0/76.2/82.8/82.2/81.0",80.63,2842.46,13758660.0,108971478.16,5571.60,"-i crowd_run_1080p50_x264.mp4 -c:v libx264 -preset veryfast -filter_scale_threads 4 -profile:v main -refs 3 -g 60 -keyint_min 60 -b:v 6M -maxrate 6M -bufsize 12M -sc_threshold 0 -r 60 -y 1080p.mp4"
  x264,1080P,="1:1",1,veryfast,crowd_run_1080p50_x264.mp4,10,61.2,="69.0/61.8/69.0/68.4/69.6/61.2/61.2/68.4/62.4/61.2",82.23,2827.07,16032820.0,17415586.69,5052.12,"-i crowd_run_1080p50_x264.mp4 -c:v libx264 -preset veryfast -filter_scale_threads 4 -profile:v main -refs 3 -g 60 -keyint_min 60 -b:v 6M -maxrate 6M -bufsize 12M -sc_threshold 0 -r 60 -y 1080p.mp4"
  x264,1080P,="1:1",1,veryfast,crowd_run_1080p50_x264.mp4,11,56.22,="56.22/57.06/59.34/59.88/56.34/57.18/59.1/59.46/59.58/58.86/57.06",82.84,2832.89,17206068.0,21058730.17,5265.87,"-i crowd_run_1080p50_x264.mp4 -c:v libx264 -preset veryfast -filter_scale_threads 4 -profile:v main -refs 3 -g 60 -keyint_min 60 -b:v 6M -maxrate 6M -bufsize 12M -sc_threshold 0 -r 60 -y 1080p.mp4"

  Total Runtime: 0:04:56.764700
   ```

First, there is the header that has general information about the run, including the ffmpeg version used:

  ```code
  FFMPEG Benchmark Results
  Run date/time,2020-08-07_09:58:33

  FFMPEG version,="n4.1.3-2-g070cee7184"
  Kernel version,="5.3.0-1032-aws"
  OS version    ,="Ubuntu 18.04.4 LTS"
  CPU model     ,="Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz"
  Config file   ,="/home/mjeronimo/src/perfkitbenchmarker/perfkitbenchmarker/data/ffmpeg/ffmpeg_benchmark_tests.yaml"
  Results dir   ,="/opt/pkb/results/results_2020-08-07_09:58:33"
  Video dir     ,="/opt/pkb/videos"
   ```

Next, there is a row of headings that describe the output of the data rows:

  ```code
  codec,input_format,output_mode,n,preset,video_file,#transcodes,lowest_fps,list_of_fps,average_cpu,average_bzy_mhz,max_pct_memused,active_read_(bytes),active_write_(bytes),ffmpeg_args
  ```

The fields are as follows:

| Field | Description |
| ----------- | ----------- |
| **codec** | The codec used (x264, x265, svt-hevc, vp9) |
| **input_format** | The format of the input video file (1080P, 4K, etc.) |
| **output_mode** | The output mode used for the run - 1:1 (1 input, 1 output), or 1:n (1 input, n outputs) |
| **n** | The number of output files for the run (1 in the case of 1:1, the 'n' value in the case of 1:n) |
| **preset** | The name of the ffmpeg preset used for the codec |
| **video_file** | The input video file |
| **\# transcodes** | The number of transcodes achieved |
| **lowest_fps** | The lowest FPS achieved for each of the instances |
| **list_of_fps** | The list of average FPS for each of the instances |
| **average_cpu** | The average CPU utilization during the run |
| **average_bzy_mhz** | The average CPU frequency during the run |
| **max_pct_memused** | The average maximum percentage of memory used during the run |
| **active_read_(bytes)** | The average active read bytes during the run |
| **active_write_(bytes)** | The average active write bytes during the run |
| **ffmpeg_args** | The argument list passed to ffmpeg (or directly to the codec in the case of direct mode) |

Then, the data collected from each pass of the run:

  ```code
  x264,1080P,="1:1",1,veryfast,crowd_run_1080p50_x264.mp4,8,76.2,="76.2/76.2/76.8/81.0/76.2/82.8/82.2/81.0",80.63,2842.46,13758660.0,108971478.16,5571.60,"-i crowd_run_1080p50_x264.mp4 -c:v libx264 -preset veryfast -filter_scale_threads 4 -profile:v main -refs 3 -g 60 -keyint_min 60 -b:v 6M -maxrate 6M -bufsize 12M -sc_threshold 0 -r 60 -y 1080p.mp4"
  x264,1080P,="1:1",1,veryfast,crowd_run_1080p50_x264.mp4,10,61.2,="69.0/61.8/69.0/68.4/69.6/61.2/61.2/68.4/62.4/61.2",82.23,2827.07,16032820.0,17415586.69,5052.12,"-i crowd_run_1080p50_x264.mp4 -c:v libx264 -preset veryfast -filter_scale_threads 4 -profile:v main -refs 3 -g 60 -keyint_min 60 -b:v 6M -maxrate 6M -bufsize 12M -sc_threshold 0 -r 60 -y 1080p.mp4"
  x264,1080P,="1:1",1,veryfast,crowd_run_1080p50_x264.mp4,11,56.22,="56.22/57.06/59.34/59.88/56.34/57.18/59.1/59.46/59.58/58.86/57.06",82.84,2832.89,17206068.0,21058730.17,5265.87,"-i crowd_run_1080p50_x264.mp4 -c:v libx264 -preset veryfast -filter_scale_threads 4 -profile:v main -refs 3 -g 60 -keyint_min 60 -b:v 6M -maxrate 6M -bufsize 12M -sc_threshold 0 -r 60 -y 1080p.mp4"
  ```

  The *#transcodes* refers to the number of simultanous instances of ffmpeg that are executed. A LIVE mode runs start with 8 ffmpeg instances, which we can see in the first row. With 8 instances, the *lowest_fps* achieved by any of the instances is 76.2, which exceeds the target frame rate for this test (60 fps). The *list_of_fps* field shows the average frame rate for each instance ("76.2/76.2/76.8/81.0/76.2/82.8/82.2/81.0"). The autoscaling algorithm then computes 10 instances for the next step and tries that. The second row shows the results for this pass: a lowest fps value of 61.2. The next step then tries 11 instances, but falls below the 60 fps threshold, achieving a lowest_fps of only 56.22. So, the optimal number of instances for this test is 10. 
  
The CSV file ends with a summary of the total runtime for the run:

  ```code
  Total Runtime: 0:04:56.764700
  ```

## 5. The FFMPEG Workload Description File

The FFMPEG workload description file uses the YAML file format. The file contains a sequence of sections, each of which defines a test case, where a test case is either a *basic test case* or a *group*. 

A basic test case is specified as follows:

```YAML
# The top-level is the name of the test case
some_test_case:             
  input_files:              # List of input video files
  input_format:             # Input format, such as 1080P or 4k
  output_mode:              # Section that describes the various output-related test parameters
    type:                   # The output mode type, such as 1:n/LIVE, 1:1/LIVE, or VOD
    fps_threshold:          # The Real Time FPS threshold for Live workloads (for example, 60).
                            # Ignored for VOD workloads
  video_codec:              # Section that descibes the video encoding-related parameters
    codec:                  # Name of the ffmpeg codec to use, such as x265 or hevc
    preset:                 # Name of the ffmpeg codec's preset to use
    tune:                   # Name of the preset's tuning value, if any (optional)
    args:                   # Any additional arguments to ffmpeg
```

For example,
	
```YAML
svt-hevc-preset6-1to1Live-4k:
  input_files: "CSGO.mp4 crowd_run_2160p50.mp4 Netflix_Tango_4096x2160_60fps_10bit_420.mp4"
  input_format: "4k"
  output_mode:
    type: "1:1/LIVE"
    fps_threshold: 60
  video_codec:
    codec: "SVT-HEVC"
    preset: 6
    args: "-rc 1 -b:v 9.6M -maxrate 9.6M -bufsize 19.2M -r 60 -g 120 4k.mp4"
```
Tests can be combined into logical groups, as follows:

```YAML
some_group_name:
  group: # A sequence of one or more names where each name is the name of another 
         # group or a basic test case
```
For example,

```YAML
svt-hevc:
  group: >-
    svt-hevc-preset6-1toNLive-1080p
    svt-hevc-preset9-1toNLive-1080p
    svt-hevc-preset6-1to1Live-4k
    svt-hevc-preset10-1to1Live-4k
    svt-hevc-preset6-1toNLive-4k
    svt-hevc-preset9-1toNLive-4k
```
Please refer to [ffmpeg_benchmark_tests.yaml](ffmpeg_benchmark_tests.yaml) for more examples.

## 6. Creating and Using a Custom FFMPEG Workload Description File

You may use the default workload file or create your own custom file. The custom file must be in the format described in the previous section and placed in the perfkitbenchmarker/data/ffmpeg directory. To use this file, invoke PKB using the *--ffmpeg_benchmark_tests* command-line option to instruct PKB to use this file instead of the default (ffmpeg_benchmark_tests.yaml). In this case, only the tests defined in the custom file will be available.

For example, let's assume you've created a benchmark description file, mytests.yaml, which contains the following:

```YAML
# perfkitbenchmarker/data/ffmpeg/mytests.yaml
vp9-example:
  description: "1080p input to 1080p output using vp9"
  input_files: "crowd_run_1080p50.mp4"
  input_format: "1080P"
  output_mode:
    type: "1:1/LIVE"
    fps_threshold: 60
  video_codec:
    codec: "vpx-vp9"
    args: "-b:v 2M 1080p.mp4"
```

You can then invoke this new test case as follows:

```bash
$ ./pkb.py <non-ffmpeg-flags-omitted> --benchmarks=ffmpeg --ffmpeg_benchmark_tests=mytests --ffmpeg_run_tests=vp9-example
```

## 7. Using Separate Provision, Prepare, and Run Stages

PKB workloads implement separate Provison, Prepare, Run, Cleanup, and Teardown stages. Normally during a run, PKB invokes each of these in succession. It is possible to manually control these run stages by specifying the stage to run using the *--run_stage* command-line argument. This could be useful, for example, to Provision and Prepare once and then perform multiple Run stages before finally, executing Cleanup and Teardown.

The following command lines show an example of using separate stages:

```bash
# First, do Provision and Prepare
$ ./pkb.py --cloud=AWS --machine_type=m5.16xlarge --os_type=ubuntu1804 --zone=us-west-2 --benchmarks=ffmpeg --ffmpeg_run_tests=x264-veryfast-1to1Live-1080p --run_stage=provision,prepare

# Next, can do multiple Run stages
$ ./pkb.py --cloud=AWS --machine_type=m5.16xlarge --os_type=ubuntu1804 --zone=us-west-2 --benchmarks=ffmpeg --ffmpeg_run_tests=x264-veryfast-1to1Live-1080p --run_stage=run

$ ./pkb.py --cloud=AWS --machine_type=m5.16xlarge --os_type=ubuntu1804 --zone=us-west-2 --benchmarks=ffmpeg --ffmpeg_run_tests=x264-veryfast-1to1Live-1080p --run_stage=run

# Finally, clean things up
$ ./pkb.py --cloud=AWS --machine_type=m5.16xlarge --os_type=ubuntu1804 --zone=us-west-2 --benchmarks=ffmpeg --ffmpeg_run_tests=x264-veryfast-1to1Live-1080p --run_stage=cleanup,teardown
```

## 8. Using Cached Input Video Files

By default, the FFMPEG workload will download and transcode video input files from the .y4m format to .mp4 during the Prepare phase. Because this operation takes a long time, there is a command-line option, *--ffmpeg_videos_dir*, that allows the user to specify a directory in which the user has stored previously prepared video files for PKB to use instead of downloading and transcoding them. Using this option can save a significant amount of time as the videos are simply copied from the PKB host to the /opt/pkb/videos directory on the system-under-test (SUT).

For example, with the following command-line the input video files will be copied from the /home/ubuntu/videos directory on the host machine:

```bash
$ ./pkb.py <non-ffmpeg-options-omitted> --benchmarks=ffmpeg --ffmpeg_run_tests=x265-medium-1to1Live-1080p --ffmpeg_videos_dir=/home/ubuntu/videos
```

## 9. Copying Prepared Videos from the SUT

One way to get the desired input video files in the .mp4 format so that they can be used with the *--ffmpeg_videos_dir* option is to run once without the option and then copy the videos from the SUT to the host so that they can be used on subsequent runs. For example, you can do the following:

* **Execute the provision and prepare stages for a test**

    ```bash
    $ ./pkb.py --cloud=AWS --machine_type=m5.16xlarge --os_type=ubuntu1804 --zone=us-west-2 --benchmarks=ffmpeg --ffmpeg_run_tests=x264,x265-medium-1to1Live-1080p --run_stage=provision,prepare
    ```

    After this step, the video files will have been downloaded and transcoded to .4ym and will reside in the /opt/pkb/videos directory on the SUT.

* **Determine IP address of the SUT, the username on the SUT, and the URI for the run**

    This can be determined from the log file for the run.

* **Copy the videos to the host using scp**
  
    For example, assume that you've determined that the IP address for the SUT is 54.202.181.105, the user name there is 'ubuntu' and the run URI is 17a3fe89, the following command will copy video files from the SUT to the current working directory on the host:

    ```bash
    $ scp -P 22 -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o IdentitiesOnly=no -o PreferredAuthentications=publickey -o PasswordAuthentication=no -o ConnectTimeout=5 -o GSSAPIAuthentication=no -o ServerAliveInterval=30 -o ServerAliveCountMax=10 -i /tmp/perfkitbenchmarker/runs/17a3fe89/perfkitbenchmarker_keyfile ubuntu@54.202.181.105:/opt/pkb/videos/*.mp4 .
    ```

* **Clean up the run**

    Make sure the complete the previous run by running the cleanup and teardown phases:

    ```bash
    $ ./pkb.py --cloud=AWS --machine_type=m5.16xlarge --os_type=ubuntu1804 --zone=us-west-2 --benchmarks=ffmpeg --ffmpeg_run_tests=x264,x265-medium-1to1Live-1080p --run_stage=cleanup,teardown --run_uri=17a3fe89
    ```

## 10. Publishing Results to the Cumulus Dashboard

The Cumulus project has a dashboard on which users can save and view workload runs. To publish the results of a run, you may use the *--kafka_publish* command-line option. It is recommended that you also use the *--owner* command-line option since the results will then be associated with this name on the dashboard, making it easier to search and sort for your output. For example, to perform a run and publish the results:

```bash
$ ./pkb.py --cloud=AWS --machine_type=m5.16xlarge --os_type=ubuntu1804 --zone=us-west-2 --benchmarks=ffmpeg --ffmpeg_run_tests=x265-medium-1to1Live-1080p --kafka_publish --owner=my_name
```

## 11. Output Modes and Autoscaling

The FFMPEG workload has two primary modes of operation: LIVE mode and VOD mode. In both cases, the FFMPEG workload attempts to find the optimal number of simultaneous ffmpeg instances to run using different *autoscaling algorithms*.

For LIVE mode, the goal is to find the maximum number of simultaneous transcodes that the platform can support while maintaining a minimum frame rate (the 'fps_threshold') for all instances. The code starts with 8 instances and then, based on the results of that pass, computes the number of instances to try for the next pass. 

For example, assuming an fps_threshold of 60, the first run might achieve the following:

```bash
  num_inst: 8
  lowest_fps: 75.0
  fps_threshold: 60
  all_last_fps: 82.0/77.0/78.0/75.0/85.0/80.0/90.0/76.0
  new_num_inst: 10
```

That is, eight simultaneous ffmpeg transcodes were run, where the lowest fps achieved by any of the instances was 75. Based on the sum of the fps rates for all of the instances (643), divided by the fps_threshold (60), we should be able to do 10 instances. So, the next pass runs 10 instances:

```bash
  num_inst: 10
  lowest_fps: 62.0
  fps_threshold: 60
  all_last_fps: 62.0/62.0/84.0/78.0/64.0/70.0/68.0/65.0/71.0/69.0
  new_num_inst: 11
```

After this pass, we see that we still maintained at least 60 fps for all instances. In fact, again computing the sum of the fps rates divided by the number of instances, we can then theoretically support 11 simultenous instances. This process continues until the lowest_fps falls below the threshold and we have already tried the number of instances proposed for the next iteration.

For VOD mode, the goal is to find the overall maximum frame rate that can be achieved by all of the instances in aggregate. The code simply starts with 1 instance and then adds an instance each pass until the overall frame rate decreases.

## 12. Using Trace Collectors, Such as EMON

For the FFMPEG workload, trace collectors are not run during the autoscaling process. Instead, if trace collection, such as EMON, is requested, the collection is run after autoscaling is complete and the optimal number of instances is determined. It then runs another pass, this time with trace collection enabled, using this number of instances. This approach is used to avoid any undesirable influence of trace collection on the results of the benchmark.

To collect EMON for a run, you must:
- Enable EMON collection with the *--emon* command-line option
- Provide the path to the compressed tar file of the EMON source code on the host system
- Provide the list of events to monitor
- Allow the workload to control when trace collection is enabled using the *--trace_allow_benchmark_control* option

For example,

```bash
$ ./pkb.py <other-options-ommited-for-clarity> --emon --emon_tarball=/home/ubuntu/emon_nda_11_8_linux_03252019.tar.bz2 --emon_event_list=/home/ubuntu/edp-v4.1/ArchitectureSpecific/Skylake/SKX-2S/skx-2s-events.txt --trace_allow_benchmark_control
```

You may optionally request post-processing of the EMON data collection using EDP. To do so, you must:
- Enable EDP processing by providing the *--edp_event_list* command-line option
- Provide the path to the compressed tar file of the EDP source code on the host system

For example,
```bash
$ ./pkb.py <other-options-ommited-for-clarity> --edp_event_list=/home/ubuntu/edp-v4.1/ArchitectureSpecific/Skylake/SKX-2S/skx-2s.xml --edp_zip=/home/mjeronimo/edp-v4.1.zip 
```

After a run, the collected EMON data is available on the host system in the result_dir.tar.gz file in the output directory for the run (/tmp/perfkitbenchmarker/\<run_id\>).

## 13. Running a Specific Number of FFMPEG Instances 

Instead of relying on the autoscaling algorithm to determine the optimal number of instances, it is possible for the user to specify the number of instances to use. To do so, you may add a num_instances value for the test in the YAML file. If the workload detects a num_instance value, it will only run that number of instances and will not attempt to scale further. One use case for this capability is to run a specific number of instances on a newly rebooted on-premises instance.

The following test shows how to include the num_instances parameter:

```YAML
svt-hevc-preset6-1to1Live-4k:
  input_files: "CSGO.mp4 crowd_run_2160p50.mp4 Netflix_Tango_4096x2160_60fps_10bit_420.mp4"
  input_format: "4k"
  num_instances: 4
  output_mode:
    type: "1:1/LIVE"
    fps_threshold: 60
  video_codec:
    codec: "SVT-HEVC"
    preset: 6
    args: "-rc 1 -b:v 9.6M -maxrate 9.6M -bufsize 19.2M -r 60 -g 120 4k.mp4"
```

## 14. Using Direct Mode

Normally, when executing benchmark tests, the FFMPEG workload invokes the ffmpeg front-end binary. The ffmpeg front-end processes the various command-line options and invokes a specific codec binary, such as x264. It is possible, however, to avoid using the ffmpeg front-end and invoke the codec binary directly. To do so, add "direct=True" for the test entry in the YAML file. Also, the command-line options specified in the args entry must be appropriate for the codec binary (not ffmpeg options).

For example, in the following test case notice the "direct: True" option under the video_codec key and that the arguments provided with the "args" key are all x264-specific command-line options.

```YAML
direct_example_x264:
  description: '1080p input to 1080P output using x264/medium'
  input_files: crowd_run_1080p50.y4m
  input_format: 1080P
  output_mode:
    type: 1:1/LIVE
    fps_threshold: 60
  video_codec:
    codec: x264
    direct: True
    args: >-
      --profile main --preset veryfast --bframes 4 --b-pyramid strict --ref 3 --keyint 60 --threads 12 --frames 1600 --min-keyint 60
      --bitrate 5500 --vbv-maxrate 5500 --vbv-bufsize 11000 --scenecut 0 --rc-lookahead 60 --crf 23.0 --tune=psnr --b-adapt=0 -o 1080p.264
```

## 15. Adding Your Own Input Videos

The videos available for use by the FFMPEG workload are defined in the file, perfkitbenchmarker/data/ffmpeg/input_videos.yaml. Currently, there is no command-line option to use a different input videos file. So, if you'd like to make another video available for use, you may add entries in this file.

This YAML file has a top-level key, *input_videos*, the value of which is a list of input videos (each entry in the list starts with the '-' character), like this:

```YAML
- url: 'https://media.xiph.org/video/derf/ElFuente/Netflix_Tango_4096x2160_60fps_10bit_420.y4m'
  archive: 'Netflix_Tango_4096x2160_60fps_10bit_420.7z'
  filename: 'Netflix_Tango_4096x2160_60fps_10bit_420'
  w: 4096
  h: 2160
  fps: 60
  bitrate: '20M'
  seconds: 5
  frames: 600
  bitdepth: 10
```

To add your own file, simply add another entry, providing the source location for the .y4m file, along with the names to use for the file when copied and compressed on the SUT. Additional metadata about the source file is required.

TODO: How to do a 720p YAML entry, including another 720p input video video?

***